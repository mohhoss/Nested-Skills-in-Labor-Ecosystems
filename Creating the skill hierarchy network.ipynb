{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Requirements and Setup Instructions\n",
    "\n",
    "This notebook requires the following data files to be placed in appropriate directories:\n",
    "\n",
    "## Required Data Sources:\n",
    "\n",
    "1. **O*NET Database Files** (place in `{basepath}/onet_data/`):\n",
    "   - `Skills Nov 2019.xlsx` - Download from O*NET Database at https://www.onetcenter.org/database.html\n",
    "   - `Abilities Nov 2019.xlsx` - From same O*NET Database\n",
    "   - `Knowledge Nov 2019.xlsx` - From same O*NET Database  \n",
    "   - `Occupation Data.txt` - O*NET occupation codes and titles\n",
    "\n",
    "2. **BLS Wage Data** (place in `{basepath}/bls_wage_data/`):\n",
    "   - `national_M2019_dl.xlsx` - Download from Bureau of Labor Statistics OES data at https://www.bls.gov/oes/\n",
    "\n",
    "3. **Historical O*NET Data** (place in `{basepath}/onet_historical/`):\n",
    "   - `EducTrainExp.9.txt` - O*NET version 5.0 education data for historical comparison\n",
    "\n",
    "4. **Processed Data Files** (create these or place in `{basepath}/processed_data/`):\n",
    "   - `binary_skill_occupation_bipartite_serrano_filtered.csv` - Binary bipartite network created using Serrano et al (2009) method\n",
    "   - `skill_dependency_data_baldwin_method.csv` - Skill dependency data computed using Baldwin (2010) method\n",
    "\n",
    "5. **Custom Data Files** (create based on your analysis):\n",
    "   - `skill_clustering_data.csv` - Skill categorizations (General/Intermediate/Specific)\n",
    "   - `occupational_education_data.csv` - Education requirements by occupation\n",
    "\n",
    "## Directory Structure:\n",
    "```\n",
    "{basepath}/\n",
    "├── onet_data/\n",
    "├── bls_wage_data/ \n",
    "├── onet_historical/\n",
    "├── processed_data/\n",
    "├── output_data/\n",
    "│   ├── figures/\n",
    "│   │   └── sensitivity_analysis/\n",
    "│   └── gephi_files/\n",
    "└── working_directory/\n",
    "    └── skill_capital_wage_distribution/\n",
    "```\n",
    "\n",
    "Set the `basepath` variable in the first code cell to point to your data directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mohhosseinioun/Library/CloudStorage/Dropbox/University/PhD/2020/Research/Skill - Capital - Wage Distribution/Code/Network Prep and Analysis\n",
      "<built-in function listdir>\n",
      "['230.0000000000001, 7.0000000000000355, 41.99999999999996', '89, 89, 89', '66.00000000000007, 78.99999999999989, 164.00000000000006']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import distanceclosure as dc\n",
    "import copy\n",
    "from collections import ChainMap\n",
    "from scipy import integrate\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "# from umap import UMAP # requires numpy version < 1.20.0\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from dfply import *\n",
    "\n",
    "## Changing Working Directory\n",
    "print(os.getcwd())\n",
    "# Set basepath to your main data directory\n",
    "# Replace with the path to your data directory containing the required datasets\n",
    "basepath = \"/path/to/your/data/directory/\"\n",
    "\n",
    "# Change to working directory containing skill-capital-wage distribution data\n",
    "os.chdir(basepath+\"working_directory/skill_capital_wage_distribution\")\n",
    "print(os.listdir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forming Skill Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  O*NET-SOC Code             Title Element ID           Element Name Scale ID  \\\n",
      "0     11-1011.00  Chief Executives    2.A.1.a  Reading Comprehension       IM   \n",
      "1     11-1011.00  Chief Executives    2.A.1.a  Reading Comprehension       LV   \n",
      "2     11-1011.00  Chief Executives    2.A.1.b       Active Listening       IM   \n",
      "3     11-1011.00  Chief Executives    2.A.1.b       Active Listening       LV   \n",
      "4     11-1011.00  Chief Executives    2.A.1.c                Writing       IM   \n",
      "\n",
      "   Scale Name  Data Value    N  Standard Error  Lower CI Bound  \\\n",
      "0  Importance        4.12  8.0            0.13            3.88   \n",
      "1       Level        4.75  8.0            0.16            4.43   \n",
      "2  Importance        4.12  8.0            0.13            3.88   \n",
      "3       Level        4.88  8.0            0.23            4.43   \n",
      "4  Importance        4.00  8.0            0.00            4.00   \n",
      "\n",
      "   Upper CI Bound Recommend Suppress Not Relevant       Date Domain Source  \n",
      "0            4.37                  N          NaN 2014-07-01       Analyst  \n",
      "1            5.07                  N            N 2014-07-01       Analyst  \n",
      "2            4.37                  N          NaN 2014-07-01       Analyst  \n",
      "3            5.32                  N            N 2014-07-01       Analyst  \n",
      "4            4.00                  N          NaN 2014-07-01       Analyst  \n",
      "  O*NET-SOC Code             Title Element ID           Element Name Scale ID  \\\n",
      "0     11-1011.00  Chief Executives  1.A.1.a.1     Oral Comprehension       IM   \n",
      "1     11-1011.00  Chief Executives  1.A.1.a.1     Oral Comprehension       LV   \n",
      "2     11-1011.00  Chief Executives  1.A.1.a.2  Written Comprehension       IM   \n",
      "3     11-1011.00  Chief Executives  1.A.1.a.2  Written Comprehension       LV   \n",
      "4     11-1011.00  Chief Executives  1.A.1.a.3        Oral Expression       IM   \n",
      "\n",
      "   Scale Name  Data Value    N  Standard Error  Lower CI Bound  \\\n",
      "0  Importance        4.50  8.0            0.19            4.13   \n",
      "1       Level        4.88  8.0            0.13            4.63   \n",
      "2  Importance        4.25  8.0            0.16            3.93   \n",
      "3       Level        4.62  8.0            0.18            4.27   \n",
      "4  Importance        4.38  8.0            0.18            4.02   \n",
      "\n",
      "   Upper CI Bound Recommend Suppress Not Relevant     Date Domain Source  \n",
      "0            4.87                  N          NaN  07/2014       Analyst  \n",
      "1            5.12                  N            N  07/2014       Analyst  \n",
      "2            4.57                  N          NaN  07/2014       Analyst  \n",
      "3            4.98                  N            N  07/2014       Analyst  \n",
      "4            4.73                  N          NaN  07/2014       Analyst  \n",
      "  O*NET-SOC Code             Title Element ID                   Element Name  \\\n",
      "0     11-1011.00  Chief Executives    2.C.1.a  Administration and Management   \n",
      "1     11-1011.00  Chief Executives    2.C.1.a  Administration and Management   \n",
      "2     11-1011.00  Chief Executives    2.C.1.b                       Clerical   \n",
      "3     11-1011.00  Chief Executives    2.C.1.b                       Clerical   \n",
      "4     11-1011.00  Chief Executives    2.C.1.c       Economics and Accounting   \n",
      "\n",
      "  Scale ID  Scale Name  Data Value     N  Standard Error  Lower CI Bound  \\\n",
      "0       IM  Importance        4.75  27.0            0.09            4.56   \n",
      "1       LV       Level        6.23  27.0            0.17            5.88   \n",
      "2       IM  Importance        2.66  27.0            0.22            2.21   \n",
      "3       LV       Level        3.50  27.0            0.41            2.66   \n",
      "4       IM  Importance        3.70  27.0            0.28            3.11   \n",
      "\n",
      "   Upper CI Bound Recommend Suppress Not Relevant     Date Domain Source  \n",
      "0            4.94                  N          NaN  07/2014     Incumbent  \n",
      "1            6.57                  N            N  07/2014     Incumbent  \n",
      "2            3.11                  N          NaN  07/2014     Incumbent  \n",
      "3            4.34                  N            N  07/2014     Incumbent  \n",
      "4            4.28                  N          NaN  07/2014     Incumbent  \n"
     ]
    }
   ],
   "source": [
    "## Loading Data\n",
    "# Load O*NET Skills data - download from O*NET Database at https://www.onetcenter.org/database.html\n",
    "skill_occ = pd.read_excel(basepath+\"onet_data/\"+\"Skills Nov 2019.xlsx\")\n",
    "\n",
    "# Load O*NET Abilities data\n",
    "ability_occ = pd.read_excel(basepath+\"onet_data/\"+\"Abilities Nov 2019.xlsx\")\n",
    "\n",
    "# Load O*NET Knowledge data  \n",
    "know_occ = pd.read_excel(basepath+\"onet_data/\"+\"Knowledge Nov 2019.xlsx\")\n",
    "\n",
    "skill_occ.loc[skill_occ['Element Name'] == \"Mathematics\", 'Element Name'] = \"Mathematics Skills\"\n",
    "know_occ.loc[know_occ['Element Name'] == \"Mathematics\", 'Element Name'] = \"Mathematics Knowledge\"\n",
    "\n",
    "print(skill_occ.head())\n",
    "print(ability_occ.head())\n",
    "print(know_occ.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale ID   occ_8_dig element_ID  Importance  Level\n",
      "0         11-1011.00    2.A.1.a        4.12   4.75\n",
      "1         11-1011.00    2.A.1.b        4.12   4.88\n",
      "2         11-1011.00    2.A.1.c        4.00   4.38\n",
      "3         11-1011.00    2.A.1.d        4.38   4.88\n",
      "4         11-1011.00    2.A.1.e        3.25   3.62\n",
      "  element_ID          element_title   type\n",
      "0    2.A.1.a  Reading Comprehension  skill\n",
      "2    2.A.1.b       Active Listening  skill\n",
      "4    2.A.1.c                Writing  skill\n",
      "6    2.A.1.d               Speaking  skill\n",
      "8    2.A.1.e     Mathematics Skills  skill\n"
     ]
    }
   ],
   "source": [
    "## Combining Skills\n",
    "### Adding Type\n",
    "skill_occ['type'] = \"skill\"\n",
    "ability_occ['type'] = \"ability\"\n",
    "know_occ['type'] = \"knowledge\"\n",
    "\n",
    "# ### Renaming Columns\n",
    "skill_occ = skill_occ.rename(columns = {'O*NET-SOC Code':'occ_8_dig', 'Element ID':'element_ID', 'Element Name':'element_title'})\n",
    "ability_occ = ability_occ.rename(columns = {'O*NET-SOC Code':'occ_8_dig', 'Element ID':'element_ID', 'Element Name':'element_title'})\n",
    "know_occ = know_occ.rename(columns = {'O*NET-SOC Code':'occ_8_dig', 'Element ID':'element_ID', 'Element Name':'element_title'})\n",
    "\n",
    "\n",
    "### Creating Skills' Names\n",
    "skills_names = pd.concat([skill_occ[['element_ID', 'element_title', 'type']],\n",
    "                          ability_occ[['element_ID', 'element_title', 'type']],\n",
    "                          know_occ[['element_ID', 'element_title', 'type']]], \n",
    "                         ignore_index=True).drop_duplicates()\n",
    "\n",
    "# Load occupation names and codes - available from O*NET Database\n",
    "occ_names = pd.read_csv(basepath+\"onet_data/\"+'Occupation Data.txt', sep = \"\\t\") \\\n",
    "    .rename(columns = {'O*NET-SOC Code':'occ_8_dig'})[['occ_8_dig','Title']]\n",
    "\n",
    "\n",
    "### Keeping Needed Columns and Pivoting Values\n",
    "skill_occ = skill_occ[['occ_8_dig', 'element_ID', 'Scale ID', 'Data Value', 'type']] \\\n",
    "    .pivot_table(index = ['occ_8_dig', 'element_ID'], columns = 'Scale ID', values = 'Data Value').reset_index(drop = False)\n",
    "ability_occ = ability_occ[['occ_8_dig', 'element_ID', 'Scale ID', 'Data Value', 'type']] \\\n",
    "    .pivot_table(index = ['occ_8_dig', 'element_ID'], columns = 'Scale ID', values = 'Data Value').reset_index(drop = False)\n",
    "know_occ = know_occ[['occ_8_dig', 'element_ID', 'Scale ID', 'Data Value', 'type']] \\\n",
    "    .pivot_table(index = ['occ_8_dig', 'element_ID'], columns = 'Scale ID', values = 'Data Value').reset_index(drop = False)\n",
    "\n",
    "### Combining Skills\n",
    "skills_occ_raw = pd.concat([skill_occ.rename(columns={'IM': 'Importance', 'LV': 'Level'}),\n",
    "                            ability_occ.rename(columns={'IM': 'Importance', 'LV': 'Level'}),\n",
    "                            know_occ.rename(columns={'IM': 'Importance', 'LV': 'Level'})],\n",
    "                           ignore_index=True)[[\"occ_8_dig\", \"element_ID\", \"Importance\", \"Level\"]]\n",
    "\n",
    "\n",
    "print(skills_occ_raw.head())\n",
    "print(skills_names.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 element_ID skill_Cluster          gen_related\n",
      "0           1  1.A.1.a.1       General              General\n",
      "1           2  1.A.1.a.2       General              General\n",
      "2           3  1.A.1.a.3       General              General\n",
      "3           4  1.A.1.a.4       General              General\n",
      "4           5  1.A.1.b.1  Intermediate  Nested Intermediate\n",
      "  element_ID  Imp_weight_Avg_Edu  Lvl_weight_Avg_Edu\n",
      "0  1.A.1.a.1               4.877               5.036\n",
      "1  1.A.1.a.2               5.001               5.158\n",
      "2  1.A.1.a.3               4.911               5.059\n",
      "3  1.A.1.a.4               5.056               5.261\n",
      "4  1.A.1.b.1               5.003               5.168\n"
     ]
    }
   ],
   "source": [
    "## Loading Other Attributes\n",
    "# Load skill clustering data - create this file with skill categorizations (General/Intermediate/Specific)\n",
    "skill_clusters = pd.read_csv(basepath+\"skill_clustering_data.csv\")\n",
    "\n",
    "skill_clusters['skill_Cluster'] = skill_clusters['skill_Cluster']. \\\n",
    "    astype(pd.CategoricalDtype(categories=[\"General\", \"Intermediate\", \"Specific\"], ordered=True))\n",
    "skill_clusters['gen_related'] = skill_clusters['gen_related']. \\\n",
    "    astype(pd.CategoricalDtype(categories=[\"General\", \"Nested Intermediate\", \"Nested Specific\", \"Un-nested Intermediate\", \"Un-nested Specific\"], ordered=True))\n",
    "\n",
    "# Load occupational education data - create from O*NET Education, Training, and Experience data\n",
    "occ_educ = pd.read_csv(basepath+\"occupational_education_data.csv\")\n",
    "skill_educ = occ_educ[['occ_8_dig' ,'Education.Avg']] \\\n",
    "    .merge(skills_occ_raw[[\"occ_8_dig\", \"element_ID\", \"Importance\"]], on = \"occ_8_dig\") \\\n",
    "    .groupby(['element_ID']).apply(lambda g: round(np.average(g['Education.Avg'], weights=g['Importance']), 3)) \\\n",
    "    .rename('Imp_weight_Avg_Edu').reset_index(drop = False) \\\n",
    "    .merge(occ_educ[['occ_8_dig' ,'Education.Avg']] \\\n",
    "        .merge(skills_occ_raw[[\"occ_8_dig\", \"element_ID\", \"Level\"]], on = \"occ_8_dig\") \\\n",
    "        .groupby(['element_ID']).apply(lambda g: round(np.average(g['Education.Avg'], weights=g['Level']), 3)) \\\n",
    "        .rename('Lvl_weight_Avg_Edu').reset_index(drop = False))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(skill_clusters.head())\n",
    "print(skill_educ.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  occ_code    a_mean\n",
      "0  00-0000   53490.0\n",
      "1  11-0000  122480.0\n",
      "2  11-1000  127070.0\n",
      "3  11-1010  193850.0\n",
      "4  11-1011  193850.0\n",
      "  element_ID  log_wage\n",
      "0  1.A.1.a.1     4.785\n",
      "1  1.A.1.a.2     4.793\n",
      "2  1.A.1.a.3     4.786\n",
      "3  1.A.1.a.4     4.801\n",
      "4  1.A.1.b.1     4.798\n"
     ]
    }
   ],
   "source": [
    "# Load BLS Occupational Employment Statistics wage data - download from https://www.bls.gov/oes/\n",
    "occ_wages = pd.read_excel(basepath + \"bls_wage_data/national_M2019_dl.xlsx\")[['occ_code', 'a_mean']]\n",
    "occ_wages.a_mean[occ_wages.a_mean == \"#\"] = 208001\n",
    "occ_wages.a_mean[occ_wages.a_mean == \"*\"] = np.nan\n",
    "occ_wages.a_mean[occ_wages.a_mean == \"**\"] = np.nan\n",
    "occ_wages.a_mean = occ_wages.a_mean.astype(float)\n",
    "\n",
    "print(occ_wages.head())\n",
    "\n",
    "skills_occ_raw_temp = skills_occ_raw[[\"occ_8_dig\", \"element_ID\", \"Level\"]]\n",
    "skills_occ_raw_temp[\"occ_code\"] = skills_occ_raw_temp[\"occ_8_dig\"].str[:7]\n",
    "occ_wages['log_wage'] = np.log10(occ_wages['a_mean'])\n",
    "\n",
    "skill_wages = occ_wages[[\"occ_code\", \"log_wage\"]] \\\n",
    "    .merge(skills_occ_raw_temp[[\"occ_code\", \"element_ID\", \"Level\"]], on = \"occ_code\").dropna() \\\n",
    "    .groupby(['element_ID']).apply(lambda g: round(np.average(g['log_wage'], weights=g['Level']), 3)) \\\n",
    "    .rename('log_wage').reset_index(drop = False)\n",
    "\n",
    "print(skill_wages.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale ID   occ_8_dig element_ID  Level occ_code\n",
      "0         11-1011.00    2.A.1.a   4.75   11-101\n",
      "1         11-1011.00    2.A.1.b   4.88   11-101\n",
      "2         11-1011.00    2.A.1.c   4.38   11-101\n",
      "3         11-1011.00    2.A.1.d   4.88   11-101\n",
      "4         11-1011.00    2.A.1.e   3.62   11-101\n",
      "...              ...        ...    ...      ...\n",
      "116155    53-7121.00    2.C.7.e   0.33   53-712\n",
      "116156    53-7121.00    2.C.8.a   2.61   53-712\n",
      "116157    53-7121.00    2.C.8.b   1.52   53-712\n",
      "116158    53-7121.00    2.C.9.a   0.93   53-712\n",
      "116159    53-7121.00    2.C.9.b   1.23   53-712\n",
      "\n",
      "[116160 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "skills_occ_raw_temp = skills_occ_raw[[\"occ_8_dig\", \"element_ID\", \"Level\"]]\n",
    "skills_occ_raw_temp[\"occ_code\"] = skills_occ_raw_temp[\"occ_8_dig\"].str[:6]\n",
    "\n",
    "print(skills_occ_raw_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Bipartite Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Out Non-essential Links and Transforming to Binary Bipartite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    occ_8_dig element_ID\n",
      "0  11-1011.00    2.A.1.a\n",
      "1  11-1011.00    2.A.1.b\n",
      "2  11-1011.00    2.A.1.c\n",
      "3  11-1011.00    2.A.1.d\n",
      "4  11-1011.00    2.A.1.e\n",
      "<bound method NDFrame.describe of         occ_8_dig element_ID\n",
      "0      11-1011.00    2.A.1.a\n",
      "1      11-1011.00    2.A.1.b\n",
      "2      11-1011.00    2.A.1.c\n",
      "3      11-1011.00    2.A.1.d\n",
      "4      11-1011.00    2.A.1.e\n",
      "...           ...        ...\n",
      "33860  53-7121.00  1.A.4.a.6\n",
      "33861  53-7121.00  1.A.4.b.1\n",
      "33862  53-7121.00  1.A.4.b.2\n",
      "33863  53-7121.00    2.C.2.a\n",
      "33864  53-7121.00    2.C.3.e\n",
      "\n",
      "[33865 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "## Approach 1: Using Serrano et al method for binary network creation\n",
    "# Load pre-computed binary bipartite network - see companion notebook for creation process\n",
    "# This file contains filtered occupation-skill connections using Serrano et al (2009) method\n",
    "bipartite_binary_edgelist = pd.read_csv(basepath+'processed_data/binary_skill_occupation_bipartite_serrano_filtered.csv')\n",
    "bipartite_binary_edgelist = bipartite_binary_edgelist[['occ_8_dig','element_ID']]\n",
    "\n",
    "\n",
    "print(bipartite_binary_edgelist.head())\n",
    "print(bipartite_binary_edgelist.describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occ_8_dig</th>\n",
       "      <th>element_ID</th>\n",
       "      <th>element_title</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13-2099.01</td>\n",
       "      <td>2.A.2.b</td>\n",
       "      <td>Active Learning</td>\n",
       "      <td>skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13-2099.01</td>\n",
       "      <td>2.A.1.b</td>\n",
       "      <td>Active Listening</td>\n",
       "      <td>skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>13-2099.01</td>\n",
       "      <td>2.C.1.a</td>\n",
       "      <td>Administration and Management</td>\n",
       "      <td>knowledge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>13-2099.01</td>\n",
       "      <td>1.A.1.b.7</td>\n",
       "      <td>Category Flexibility</td>\n",
       "      <td>ability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13-2099.01</td>\n",
       "      <td>2.B.2.i</td>\n",
       "      <td>Complex Problem Solving</td>\n",
       "      <td>skill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     occ_8_dig element_ID                  element_title       type\n",
       "6   13-2099.01    2.A.2.b                Active Learning      skill\n",
       "1   13-2099.01    2.A.1.b               Active Listening      skill\n",
       "38  13-2099.01    2.C.1.a  Administration and Management  knowledge\n",
       "30  13-2099.01  1.A.1.b.7           Category Flexibility    ability\n",
       "14  13-2099.01    2.B.2.i        Complex Problem Solving      skill"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bipartite_binary_edgelist.loc[bipartite_binary_edgelist.occ_8_dig == \"13-2099.01\"]. \\\n",
    "    merge(skills_names, on = \"element_ID\").sort_values(by = \"element_title\").head()\n",
    "# print(bipartite_binary_edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occupations that have both Math Skill and Programming\n",
      "      Math element_ID                     Title\n",
      "0  2.A.1.e    2.B.3.e             Statisticians\n",
      "1  2.A.1.e    2.B.3.e  Mathematical Technicians\n",
      "2  2.A.1.e    2.B.3.e       Mapping Technicians\n",
      "3  2.A.1.e    2.B.3.e                Biologists\n",
      "4  2.A.1.e    2.B.3.e                Physicists\n",
      "Occupations that have Math Skill but not Programming\n",
      "        Math element_ID                                              Title\n",
      "99   2.A.1.e        NaN                           Food Science Technicians\n",
      "3    2.A.1.e        NaN                                     Sales Managers\n",
      "76   2.A.1.e        NaN                                  Animal Scientists\n",
      "178  2.A.1.e        NaN  Grinding, Lapping, Polishing, and Buffing Mach...\n",
      "142  2.A.1.e        NaN           Sales Agents, Securities and Commodities\n",
      "15   2.A.1.e        NaN        Purchasing Agents and Buyers, Farm Products\n",
      "162  2.A.1.e        NaN                                       Order Clerks\n",
      "188  2.A.1.e        NaN                                           Jewelers\n",
      "100  2.A.1.e        NaN                             Biological Technicians\n",
      "122  2.A.1.e        NaN             Home Economics Teachers, Postsecondary\n",
      "28   2.A.1.e        NaN                            Appraisers, Real Estate\n",
      "54   2.A.1.e        NaN                            Environmental Engineers\n",
      "126  2.A.1.e        NaN                  Farm and Home Management Advisors\n",
      "115  2.A.1.e        NaN                  Chemistry Teachers, Postsecondary\n",
      "32   2.A.1.e        NaN                        Personal Financial Advisors\n",
      "149  2.A.1.e        NaN  First-Line Supervisors/Managers of Office and ...\n",
      "36   2.A.1.e        NaN                                      Loan Officers\n",
      "163  2.A.1.e        NaN                           Cargo and Freight Agents\n",
      "137  2.A.1.e        NaN  First-Line Supervisors/Managers of Retail Sale...\n",
      "128  2.A.1.e        NaN                                 Interior Designers\n",
      "29   2.A.1.e        NaN                                    Budget Analysts\n",
      "109  2.A.1.e        NaN           Computer Science Teachers, Postsecondary\n",
      "16   2.A.1.e        NaN  Wholesale and Retail Buyers, Except Farm Products\n",
      "161  2.A.1.e        NaN                                New Accounts Clerks\n",
      "74   2.A.1.e        NaN                 Industrial Engineering Technicians\n",
      "56   2.A.1.e        NaN           Fire-Prevention and Protection Engineers\n",
      "127  2.A.1.e        NaN                Commercial and Industrial Designers\n",
      "27   2.A.1.e        NaN                                          Assessors\n",
      "170  2.A.1.e        NaN                            Log Graders and Scalers\n",
      "52   2.A.1.e        NaN                               Electrical Engineers\n",
      "189  2.A.1.e        NaN                            Gem and Diamond Workers\n",
      "31   2.A.1.e        NaN                                 Financial Analysts\n",
      "20   2.A.1.e        NaN                  Insurance Appraisers, Auto Damage\n",
      "35   2.A.1.e        NaN                                    Loan Counselors\n",
      "174  2.A.1.e        NaN               Cement Masons and Concrete Finishers\n",
      "167  2.A.1.e        NaN                            Insurance Claims Clerks\n",
      "62   2.A.1.e        NaN  Mining and Geological Engineers, Including Min...\n",
      "124  2.A.1.e        NaN  Secondary School Teachers, Except Special and ...\n",
      "65   2.A.1.e        NaN                             Architectural Drafters\n",
      "157  2.A.1.e        NaN                                   Brokerage Clerks\n",
      "22   2.A.1.e        NaN                                    Cost Estimators\n",
      "173  2.A.1.e        NaN                            Tile and Marble Setters\n",
      "84   2.A.1.e        NaN         Medical Scientists, Except Epidemiologists\n",
      "125  2.A.1.e        NaN  Adult Literacy, Remedial Education, and GED Te...\n",
      "186  2.A.1.e        NaN  Petroleum Pump System Operators, Refinery Oper...\n",
      "47   2.A.1.e        NaN                                Aerospace Engineers\n",
      "10   2.A.1.e        NaN                              Construction Managers\n",
      "87   2.A.1.e        NaN                   Atmospheric and Space Scientists\n",
      "158  2.A.1.e        NaN                              Correspondence Clerks\n",
      "119  2.A.1.e        NaN                  Geography Teachers, Postsecondary\n",
      "Occupations that have Programming but not Math Skills\n",
      "  Math element_ID               Title\n",
      "7  NaN    2.B.3.e  Computer Operators\n",
      "      Math element_ID                                              Title\n",
      "0  2.A.1.e        NaN  Secondary School Teachers, Except Special and ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Occupations that have both Math Skill and Programming\")\n",
    "print(bipartite_binary_edgelist.loc[bipartite_binary_edgelist.element_ID == \"2.A.1.e\"].rename(columns = {\"element_ID\":\"Math\"}). \\\n",
    "    merge(bipartite_binary_edgelist.loc[bipartite_binary_edgelist.element_ID == \"2.B.3.e\"], how = \"inner\"). \\\n",
    "      merge(occ_names, on = \"occ_8_dig\")[['Math','element_ID','Title']].head())\n",
    "\n",
    "print(\"Occupations that have Math Skill but not Programming\")\n",
    "temp = bipartite_binary_edgelist.loc[bipartite_binary_edgelist.element_ID == \"2.A.1.e\"].rename(columns = {\"element_ID\":\"Math\"}). \\\n",
    "    merge(bipartite_binary_edgelist.loc[bipartite_binary_edgelist.element_ID == \"2.B.3.e\"], how = \"left\"). \\\n",
    "      merge(occ_names, on = \"occ_8_dig\")[['Math','element_ID','Title']]\n",
    "print(temp[temp['element_ID'].isnull()].sample(50))\n",
    "\n",
    "print(\"Occupations that have Programming but not Math Skills\")\n",
    "temp = bipartite_binary_edgelist.loc[bipartite_binary_edgelist.element_ID == \"2.A.1.e\"].rename(columns = {\"element_ID\":\"Math\"}). \\\n",
    "    merge(bipartite_binary_edgelist.loc[bipartite_binary_edgelist.element_ID == \"2.B.3.e\"], how = \"right\"). \\\n",
    "     merge(occ_names, on = \"occ_8_dig\")[['Math','element_ID','Title']]\n",
    "print(temp[temp['Math'].isnull()].head())\n",
    "\n",
    "#17-1011.00: Architects; 11-1011.00: CEO; 25-2031.00: secondary school teacher;\n",
    "# 19-2012.00: Physist; 29-1041.00: optometrist\n",
    "print(bipartite_binary_edgelist.loc[(bipartite_binary_edgelist.element_ID == \"2.A.1.e\") & \\\n",
    "                                    (bipartite_binary_edgelist.occ_8_dig == \"25-2031.00\")].rename(columns = {\"element_ID\":\"Math\"}). \\\n",
    "    merge(bipartite_binary_edgelist.loc[(bipartite_binary_edgelist.element_ID == \"2.B.3.e\") & \\\n",
    "                                        (bipartite_binary_edgelist.occ_8_dig == \"25-2031.00\")], how = \"left\"). \\\n",
    "     merge(occ_names, on = \"occ_8_dig\")[['Math','element_ID','Title']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Edgelist to Bipartite Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11-1011.00', '11-1011.03', '11-1021.00', '11-2011.00', '11-2021.00', '11-2022.00', '11-2031.00', '11-3011.00', '11-3021.00', '11-3031.01']\n",
      "[('11-1011.00', '2.A.1.a'), ('11-1011.00', '2.A.1.b'), ('11-1011.00', '2.A.1.c'), ('11-1011.00', '2.A.1.d'), ('11-1011.00', '2.A.1.e'), ('11-1011.00', '2.A.2.a'), ('11-1011.00', '2.A.2.b'), ('11-1011.00', '2.A.2.c'), ('11-1011.00', '2.A.2.d'), ('11-1011.00', '2.B.1.a')]\n",
      "33865\n"
     ]
    }
   ],
   "source": [
    "# skill_occ_B = from_pandas_dataframe(bipartite_binary_edgelist)\n",
    "\n",
    "skill_occ_B = nx.Graph()\n",
    "skill_occ_B.add_nodes_from(bipartite_binary_edgelist['occ_8_dig'], bipartite=0)\n",
    "skill_occ_B.add_nodes_from(bipartite_binary_edgelist['element_ID'], bipartite=1) # *** Remember that Skills are at dim 1 ***\n",
    "skill_occ_B.add_edges_from(\n",
    "    [(row['occ_8_dig'], row['element_ID']) for idx, row in bipartite_binary_edgelist.iterrows()])\n",
    "\n",
    "# skill_occ_B = nx.from_pandas_edgelist(bipartite_binary_edgelist.rename(columns = {'occ_8_dig':\"source\", 'element_ID':\"target\"}), \\\n",
    "#                                       create_using=nx.DiGraph())\n",
    "\n",
    "print(list(skill_occ_B.nodes)[0:10])\n",
    "print(list(skill_occ_B.edges)[0:10])\n",
    "print(len(list(skill_occ_B.edges)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code for Jo et al 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## The Function Code from https://github.com/wooseongjo/hier-backbone/blob/master/hier_backbone/core.py\n",
    "\n",
    "\"\"\"  \n",
    "** Core library to extract hierarchical skill network. \n",
    "** Version: 0.8\n",
    "** Date: April. 16. 2018\n",
    "** Python version >= 3.x || >= 2.6\n",
    "\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import networkx as nx\n",
    "import itertools, math, pickle, sys, re \n",
    "\n",
    "\n",
    "def write_edges(f, G, **kwargs):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        1. file object: f\n",
    "        2. graph object: G\n",
    "    Output: \n",
    "        None\n",
    "    \n",
    "    Write edges (u, v) (direction: u ->v) with hierarchical measure alpha\n",
    "    \"\"\"\n",
    "    try:\n",
    "        weight_col = kwargs['weight']\n",
    "    except:\n",
    "        weight_col = 'weight'\n",
    "\n",
    "    for u, v in G.edges_iter():\n",
    "        f.write(\"%s\\t%s\\t%f\\n\" % (str(u), str(v), float(G[u][v][weight_col])) )\n",
    "\n",
    "    f.close()\n",
    "\n",
    "def parsimony_network(G):\n",
    "    G_parsi = G.copy()\n",
    "\n",
    "    n_list = list(G_parsi.nodes())\n",
    "    direct_path_list = []\n",
    "\n",
    "    for node in n_list:\n",
    "        nn_set = set(G_parsi.successors(node))\n",
    "        bfs_reachable_nodes = set()\n",
    "\n",
    "        for nn in list(nn_set):\n",
    "            bfs_dic = nx.bfs_successors(G_parsi, nn)\n",
    "            bfs_reachable_nodes = bfs_reachable_nodes | set( [n for s, nn in bfs_dic for n in nn ] )\n",
    "\n",
    "        cur_direct_path = bfs_reachable_nodes & nn_set\n",
    "\n",
    "        for nn in list(cur_direct_path):\n",
    "            direct_path_list.append((node, nn))\n",
    "    \n",
    "    print(\"Remove %d direct paths in G\" % len(direct_path_list))\n",
    "\n",
    "    G_parsi.remove_edges_from(direct_path_list)\n",
    "\n",
    "    return G_parsi\n",
    "\n",
    "\n",
    "def projection_from_list(tag_deg_list, tag_co_list, item_size, **kwargs):\n",
    "\n",
    "    try:\n",
    "        z_score_thres = float(kwargs['zscore'])\n",
    "    except:\n",
    "        z_score_thres = 2.0\n",
    "\n",
    "    nofnode_pair_axis = int(item_size)\n",
    "    tag_deg_dic = {}\n",
    "    cp = {}\n",
    "    edge_dic_filtered = {}\n",
    "\n",
    "    for tag, deg in tag_deg_list:\n",
    "        tag_deg_dic[tag] = int(deg)\n",
    "\n",
    "    totlen = len(tag_co_list)\n",
    "    thres_percent = 1\n",
    "    \n",
    "    for tag_node, deg in tag_deg_list:\n",
    "        edge_dic_filtered[tag_node] = []\n",
    "    \n",
    "    for idx, (u, v, co_occur) in enumerate(tag_co_list):\n",
    "        len_v_nn = float(tag_deg_dic[v])\n",
    "        len_u_nn = float(tag_deg_dic[u])\n",
    "        common_nn = float(co_occur)\n",
    "\n",
    "        average = len_v_nn * len_u_nn / nofnode_pair_axis\n",
    "        deviation = math.sqrt(len_v_nn * len_u_nn * (nofnode_pair_axis - len_v_nn) * (nofnode_pair_axis - len_u_nn) \\\n",
    "                / (nofnode_pair_axis * nofnode_pair_axis * (nofnode_pair_axis-1) )  )\n",
    "\n",
    "        if ((common_nn - average)/deviation) >= z_score_thres:\n",
    "            cp[(u, v)] = common_nn / len_v_nn\n",
    "            cp[(v, u)] = common_nn / len_u_nn\n",
    "            edge_dic_filtered[u].append(v)\n",
    "            edge_dic_filtered[v].append(u)\n",
    "        else:\n",
    "            #print(u, v, (common_nn - average)/deviation) \n",
    "            pass\n",
    "\n",
    "        if( (idx / float(totlen)*100.) > thres_percent):\n",
    "            print(\"Progress: %d%%\" % (int)(idx / float(totlen) * 100.0), end=\"\\r\")\n",
    "            thres_percent += 1\n",
    "\n",
    "    print(\"= Finish removing noisy-like edges & calculating conditional probability.\")\n",
    "\n",
    "    return edge_dic_filtered, cp\n",
    "\n",
    "\n",
    "\n",
    "def projection_from_con(con, **kwargs):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        1. list of connections [ (u, v), (w, x), ... , (k, t)]\n",
    "        2. keyword arguemnt: axis= 0 or 1\n",
    "           the list \"con\" has two dimension for its elements.\n",
    "           Axis determines the dimension of node layer which \n",
    "           the bipartite network will projected onto.\n",
    "\n",
    "           For example, \n",
    "               with the keyword of axis = 1, \n",
    "               an projection network with nodes in second dimension of \n",
    "               connection list is generated.\n",
    "         \n",
    "    \n",
    "    Output: \n",
    "        1. dictionary of edges {v: [u, w, x, ...], w: [v, a, c, ...] }\n",
    "        2. dictionary of conditional probability\n",
    "            {(u,v): value, (v,u):value, (x,y):value, ... }\n",
    "            Note: conditional prob. is asymmetric for commutation of two nodes.\n",
    "            cp[(u,v)] != cp[(v, u)]\n",
    "\n",
    "    \"\"\"\n",
    "    if kwargs[\"axis\"] == 0:\n",
    "        axis = 0\n",
    "        pair_axis = 1\n",
    "    elif kwargs[\"axis\"] == 1:\n",
    "        axis = 1\n",
    "        pair_axis = 0\n",
    "    else:\n",
    "        print(\"axis: 0 or 1\")\n",
    "    \n",
    "    try:\n",
    "        z_score_thres = float(kwargs['zscore'])\n",
    "    except:\n",
    "        z_score_thres = 2.0\n",
    "        \n",
    "    \n",
    "    print(\"-Make a dictionary\")\n",
    "    ## make a dic\n",
    "    proj_dic = {}\n",
    "    for elem in con:\n",
    "        if elem[pair_axis] in proj_dic.keys():\n",
    "            proj_dic[elem[pair_axis]].append(elem[axis])\n",
    "        else:\n",
    "            proj_dic[elem[pair_axis]] = [elem[axis]]\n",
    "    \n",
    "    print(\"-Ready to project the network\")\n",
    "    print(\"-Read %d nodes in the pair-axis layer\" % len(proj_dic.keys()))\n",
    "    print(\"-Projecting the biparitite network\")\n",
    "    #make edge list\n",
    "    \n",
    "    edge_list = {}\n",
    "    \n",
    "    thres_percent = 1\n",
    "    totlen = len(proj_dic.keys())\n",
    "    cnt = 0\n",
    "    \n",
    "    for key in proj_dic.keys():\n",
    "        for node in proj_dic[key]:\n",
    "            if node in edge_list.keys():\n",
    "                edge_list[node] = edge_list[node].union(proj_dic[key])\n",
    "            else:\n",
    "                edge_list[node] = set(proj_dic[key])\n",
    "        \n",
    "        cnt += 1\n",
    "        if( (cnt / float(totlen)*100.) > thres_percent):\n",
    "            print(\"Progress: %d%%\" % (int)(cnt / float(totlen) * 100.0), end=\"\\r\")\n",
    "            thres_percent += 1\n",
    "    print(\"=Complete to make projection network\")\n",
    "    \n",
    "    for node in edge_list.keys():\n",
    "        edge_list[node] = list(edge_list[node] - set([node]))\n",
    "            \n",
    "    nofnode_pair_axis = len(proj_dic.keys())\n",
    "    del proj_dic\n",
    "    \n",
    "    print(\"-Make a dictionary\")\n",
    "    proj_dic2 = {}\n",
    "    for elem in con:\n",
    "        if elem[axis] in proj_dic2.keys():\n",
    "            proj_dic2[elem[axis]].append(elem[pair_axis])\n",
    "        else:\n",
    "            proj_dic2[elem[axis]] = [elem[pair_axis]]\n",
    "    \n",
    "    for key in proj_dic2.keys():\n",
    "        proj_dic2[key] = set(proj_dic2[key])\n",
    "        \n",
    "    deg_dic = {}\n",
    "    cp= {}\n",
    "    edge_dic_filtered = {}\n",
    "    \n",
    "    for u in proj_dic2.keys():\n",
    "        deg_dic[u] = 0\n",
    "        edge_dic_filtered[u] = []\n",
    "        \n",
    "    print(\"-Ready to remove random edges (z-score thres: %f)\" % z_score_thres)\n",
    "    print(\"-Read %d nodes in the axis layer\" % len(proj_dic2.keys()))\n",
    "    print(\"-Calculating z-score and conditional prob. for all edges in the projection network\")   \n",
    "    thres_percent = 1\n",
    "    totlen = len(edge_list.keys())\n",
    "    cnt = 0        \n",
    "    \n",
    "    z_scores = []\n",
    "    for u in edge_list.keys():\n",
    "        for v in edge_list[u]:\n",
    "            len_v_nn = float(len(proj_dic2[v]))\n",
    "            len_u_nn = float(len(proj_dic2[u]))\n",
    "            common_nn = float(len(proj_dic2[v] & proj_dic2[u]))\n",
    "        \n",
    "            #print(u, v, len_v_nn, len_u_nn, nofnode_pair_axis)\n",
    "            average = len_v_nn * len_u_nn / nofnode_pair_axis\n",
    "            deviation = math.sqrt(len_v_nn * len_u_nn * (nofnode_pair_axis - len_v_nn) * (nofnode_pair_axis - len_u_nn) \\\n",
    "                              / (nofnode_pair_axis * nofnode_pair_axis * (nofnode_pair_axis-1) )  )\n",
    "\n",
    "            z_scores.append(((common_nn - average)/deviation))\n",
    "            if deviation == 0 or ((common_nn - average)/deviation) >= z_score_thres:\n",
    "                cp[(u, v)] = common_nn / len_v_nn\n",
    "                cp[(v, u)] = common_nn / len_u_nn\n",
    "                edge_dic_filtered[u].append(v)\n",
    "                edge_dic_filtered[v].append(u)\n",
    "            else:\n",
    "                #print(u, v, (common_nn - average)/deviation) \n",
    "                pass\n",
    "        \n",
    "        cnt += 1\n",
    "        \n",
    "        if( (cnt / float(totlen)*100.) > thres_percent):\n",
    "            print(\"Progress: %d%%\" % (int)(cnt / float(totlen) * 100.0), end=\"\\r\")\n",
    "            thres_percent += 1\n",
    "            \n",
    "    print(\"=Complete to calculate conditional probability and remove random edges\")\n",
    "    \n",
    "    print(\"Visualizing Distribution of Z-scores\")\n",
    "#     plt.hist(z_scores, 50)\n",
    "    return edge_dic_filtered, cp\n",
    "    \n",
    "\n",
    "def extract_hierarchical_subgraph_from_edges(edge_dic, cp, thres, **kwargs):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        1. edge_dic: dictionary of edges such as {u: [u, w, x, ...] }\n",
    "        2. cp: dictionary of conditional probability obtained from the function\n",
    "               of projection_from_con().\n",
    "        3. thres: threshold value of alpha. \n",
    "                When you input 0 to thres, it generate the whole projection \n",
    "                network.\n",
    "\n",
    "    Output:\n",
    "        Networkx DiGraph for hierarchical subgraph \n",
    "    \"\"\"\n",
    "    max_k = max(list(len(v) for v in edge_dic.values()))\n",
    "    \n",
    "    thres_percent = 1\n",
    "    totlen = len(edge_dic.keys())\n",
    "    cnt = 0   \n",
    "\n",
    "    if not 'output' in kwargs.keys():\n",
    "        kwargs['output'] = \"graph\"\n",
    "    \n",
    "    if kwargs['output'] == \"graph\":\n",
    "        print(\"-Option: return graph object\")\n",
    "        print(\"-Calculate the hierarchy measure, alpha\")\n",
    "        edges_bunch = []\n",
    "\n",
    "        for u in edge_dic.keys():\n",
    "            for v in edge_dic[u]:\n",
    "                min_deg = float(min([len(edge_dic[u]), len(edge_dic[v])]))\n",
    "                asym = abs(cp[(u,v)] - cp[(v, u)])\n",
    "                alpha = round(min_deg * asym / max_k, 4)\n",
    "        \n",
    "                if alpha > thres:\n",
    "                    if cp[(u,v)] > cp[(v, u)]: # root: u\n",
    "                        edges_bunch.append([u, v, alpha])\n",
    "                    elif cp[(u,v)] < cp[(v, u)]:  #root: v\n",
    "                        edges_bunch.append([v, u, alpha])\n",
    "                    else:\n",
    "                        edges_bunch.append([u, v, alpha])\n",
    "                        edges_bunch.append([v, u, alpha])\n",
    "\n",
    "    \n",
    "            cnt += 1\n",
    "    \n",
    "            if( (cnt / float(totlen)*100.) > thres_percent):\n",
    "                print(\"Progress: %d%%\" % (int)(cnt / float(totlen) * 100.0), end=\"\\r\")\n",
    "                thres_percent += 1 \n",
    "        \n",
    "        print(\"=Complete the calculation of hierarhcy measure\")\n",
    "        print(\"-Making graph object using NetworkX\")\n",
    "        subG = nx.DiGraph()\n",
    "        subG.add_weighted_edges_from(edges_bunch, 'alpha')\n",
    "        print(\"=Complete!\")\n",
    "        \n",
    "        return subG\n",
    "    \n",
    "    elif kwargs['output'] == 'file':\n",
    "        try:\n",
    "            fn = kwargs['fn']\n",
    "        except KeyError:\n",
    "            print(\"Input file name as keywords: fn=\\'alpha.txt\\'\")\n",
    "        \n",
    "        \n",
    "        fs = open(fn, 'w')\n",
    "        fs.write(\"#Direction: u --> v\\n\")\n",
    "        fs.write(\"#u\\tv\\talpha\\n\")\n",
    "\n",
    "        print(\"-Option: write results in given file\")\n",
    "        print(\"-Calculate the hierarchy measure, alpha\")\n",
    "        #for u, v in edge_pair_list:\n",
    "        for u in edge_dic.keys():\n",
    "            for v in edge_dic[u]:\n",
    "                min_deg = float(min([len(edge_dic[u]), len(edge_dic[v])]))\n",
    "                asym = abs(cp[(u,v)] - cp[(v, u)])\n",
    "                alpha = min_deg * asym / max_k\n",
    "                 \n",
    "                if alpha > thres:\n",
    "                    if cp[(u,v)] > cp[(v, u)]: # root: u\n",
    "                        fs.write(\"%s\\t%s\\t%f\\n\" % (u, v, alpha) )\n",
    "                    elif cp[(u,v)] < cp[(v, u)]:  #root: v\n",
    "                        fs.write(\"%s\\t%s\\t%f\\n\" % (v, u, alpha) )\n",
    "                    else:\n",
    "                        fs.write(\"%s\\t%s\\t%f\\n\" % (u, v, alpha) )\n",
    "                        fs.write(\"%s\\t%s\\t%f\\n\" % (v, u, alpha) )\n",
    "    \n",
    "            cnt += 1\n",
    "    \n",
    "            if( (cnt / float(totlen)*100.) > thres_percent):\n",
    "                print(\"Progress: %d%%\" % (int)(cnt / float(totlen) * 100.0), end=\"\\r\")\n",
    "                thres_percent += 1 \n",
    "        \n",
    "        print(\"Save the result to %s\" % fn)\n",
    "        fs.close()\n",
    "\n",
    "\n",
    "def edges_file_to_graph(f):\n",
    "\n",
    "    hbG = nx.DiGraph()\n",
    "    \n",
    "    cnt = 0\n",
    "    thres_cnt = 100\n",
    "\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line: break\n",
    "        if line[0] == \"#\": continue\n",
    "        elem = re.split(\"\\t|\\n\", line)\n",
    "        hbG.add_edge(elem[0], elem[1], {'weight':float(elem[2])})\n",
    "        cnt+=1\n",
    "\n",
    "        if ( cnt / 100.) > thres_cnt:\n",
    "            print(\"Read edges: %d\" % cnt, end=\"\\r\")\n",
    "            thres_cnt += 100\n",
    "\n",
    "    \n",
    "    return hbG\n",
    "\n",
    "\n",
    "def bipartite_projection(B, target_node_list):\n",
    "    \"\"\"\n",
    "    Input\n",
    "        B: bipartite network\n",
    "        target_node_list: a bunch of nodes divided to be parallelized \n",
    "        output: instance of Queue\n",
    "\n",
    "    Output:\n",
    "        returns edge list with weight \n",
    "        [[u, v, w], [u, v, w], ... ]\n",
    "\n",
    "    Find connections from a bunch of nodes to make projection network\n",
    "    It returns edge list with weight such as [u, v, weight]\n",
    "\n",
    "    \"\"\"\n",
    "    r = []\n",
    "    pred=B.adj\n",
    "    totlen = len(target_node_list)\n",
    "    cnt=0\n",
    "    thres_percent = 1\n",
    "    for u in target_node_list:\n",
    "        unbrs = set(B[u])\n",
    "        nbrs2 = set((n for nbr in unbrs for n in B[nbr])) - set([u])\n",
    "        for v in nbrs2:\n",
    "            vnbrs = set(pred[v])\n",
    "            common = unbrs & vnbrs\n",
    "            weight = len(common)\n",
    "            r.append([u, v, weight])\n",
    "\n",
    "        cnt+=1\n",
    "        if( (cnt / float(totlen) * 100.) > thres_percent):\n",
    "            print(\"Process: %d%%,  Used memory: %d\" % ((int)(cnt / float(totlen) * 100.), len(r) ))\n",
    "            thres_percent += 1\n",
    "    \n",
    "    r2 = [ [u, v, {'weight': w}] for u, v, w in r ]\n",
    "    proG = nx.Graph()\n",
    "    proG.add_edges_from(r2)\n",
    "\n",
    "    return proG\n",
    "\n",
    "\n",
    "def zscore(Q, Qi, Qj, Qij):\n",
    "    \"\"\"\n",
    "    Calculate z-score from probability of co-occurance \n",
    "    between two any skills in the given biparaite network.\n",
    "    \n",
    "    Inputs:\n",
    "        Q  : The number of users \n",
    "        Qi : The number of users who connect to i-th skill \n",
    "        Qj : The number of users who connect to j-th skill.\n",
    "        Qij: The number of users who connect to both of \n",
    "            the i-th skill and the j-th skill.\n",
    "    \n",
    "    Return:\n",
    "        It returns z-score value.\n",
    "    \"\"\"\n",
    "\n",
    "    average = float(Qj)*float(Qi)/float(Q) \n",
    "    deviation = math.sqrt(Qi*Qj*(Q-Qi)*(Q-Qj) / float(Q*Q*(Q-1)) ) \n",
    "\n",
    "    return (Qij - average) / deviation\n",
    "\n",
    "\n",
    "def find_communities_from_hierarchy(G, **kwargs):\n",
    "    newman_ziff_dic = {}\n",
    "    comm_dic = {}\n",
    "\n",
    "    #### Check the prev_hier\n",
    "    if \"prev_hier\" in kwargs.keys() and \"new_edge\" in kwargs.keys():\n",
    "        prev_hier = kwargs[\"prev_hier\"]\n",
    "        new_edge = kwargs[\"new_edge\"]\n",
    "        \n",
    "        newman_ziff_dic = prev_hier.copy()\n",
    "        \n",
    "        ## new_edge: (u, v)\n",
    "        ## Direction: u -> v\n",
    "        ## if u node is incoming in the graph G, find its root\n",
    "        if not u in prev_hier.keys() and not v in prev_hier.keys():\n",
    "           newman_ziff_dic[u] = -1 \n",
    "           newman_ziff_dic[v] = u \n",
    "        \n",
    "        elif u in prev_hier.keys() and not v in prev_hier.keys():\n",
    "           newman_ziff_dic[v] = u \n",
    "        elif not u in prev_hier.keys() and v in prev_hier.keys():\n",
    "            newman_ziff_dic[u] = -1 \n",
    "            \n",
    "            ## update v's parent\n",
    "            max_weight = 0\n",
    "            for parent in G.in_edges(v):\n",
    "                if G[parent][v]['weight'] > max_weight:\n",
    "                    parent_node = parent\n",
    "            newman_ziff_dic[v] = parent_node\n",
    "        \n",
    "        else:\n",
    "            ## update u's parent\n",
    "            max_weight = 0\n",
    "            for parent in G.in_edges(u):\n",
    "                if G[parent][u]['weight'] > max_weight:\n",
    "                    parent_node = parent\n",
    "            newman_ziff_dic[u] = parent_node\n",
    "        \n",
    "            ## update v's parent\n",
    "            max_weight = 0\n",
    "            for parent in G.in_edges(v):\n",
    "                if G[parent][v]['weight'] > max_weight:\n",
    "                    parent_node = parent\n",
    "            newman_ziff_dic[v] = parent_node\n",
    "\n",
    "        ### find communities\n",
    "        for u in newman_ziff_dic.keys():\n",
    "            comm_dic[u] = find_root_hierarchy_from_newman_ziff(newman_ziff_dic, u)                   \n",
    "\n",
    "    else:\n",
    "        ## find the most probable parent node\n",
    "        for u in G.nodes_iter():\n",
    "            if G.in_degree(u) == 0:\n",
    "                newman_ziff_dic[u] = -1\n",
    "            else:\n",
    "                max_weight = 0\n",
    "                for parent, cur_u in G.in_edges(u):\n",
    "                    if G[parent][cur_u]['weight'] > max_weight:\n",
    "                        max_weight = G[parent][cur_u]['weight'] \n",
    "                        parent_node = parent\n",
    "                newman_ziff_dic[u] = parent_node\n",
    "        \n",
    "        ### find communities\n",
    "        for u in newman_ziff_dic.keys():\n",
    "            comm_dic[u] = find_root_hierarchy_from_newman_ziff(newman_ziff_dic, u)                   \n",
    "\n",
    "    return comm_dic, newman_ziff_dic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-Step of Jo et al (2020) Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: One-side Projection - for us skills in dimension 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Make a dictionary\n",
      "-Ready to project the network\n",
      "-Read 968 nodes in the pair-axis layer\n",
      "-Projecting the biparitite network\n",
      "=Complete to make projection network\n",
      "-Make a dictionary\n",
      "-Ready to remove random edges (z-score thres: 4.750000)\n",
      "-Read 120 nodes in the axis layer\n",
      "-Calculating z-score and conditional prob. for all edges in the projection network\n",
      "=Complete to calculate conditional probability and remove random edges\n",
      "Visualizing Distribution of Z-scores\n",
      "('2.A.1.a', ['2.C.4.d', '1.A.1.b.2', '2.C.9.b', '2.C.5.b', '2.A.1.e', '2.B.5.b', '2.B.3.a', '2.A.1.b', '1.A.1.b.5', '1.A.1.b.6', '2.B.5.a', '2.B.4.h', '2.C.7.a', '2.B.1.f', '2.C.4.f', '1.A.1.b.3', '2.C.1.a', '2.C.4.b', '2.B.5.d', '1.A.1.e.2', '2.C.7.e', '2.A.2.a', '1.A.1.b.4', '1.A.1.c.2', '2.A.2.d', '2.C.8.b', '1.A.1.b.7', '2.C.1.b', '2.C.1.e', '1.A.4.b.5', '2.B.1.d', '2.A.1.f', '2.C.4.a', '1.A.4.b.4', '2.A.2.b', '2.B.4.e', '1.A.1.c.1', '2.A.1.c', '2.B.1.b', '1.A.4.a.1', '2.B.2.i', '2.A.2.c', '1.A.1.e.1', '1.A.1.a.3', '2.C.4.g', '1.A.1.a.4', '2.C.5.a', '2.A.1.d', '1.A.1.a.2', '2.B.4.g', '2.B.1.c', '2.C.4.e', '2.C.1.f', '2.C.6', '1.A.1.a.1', '2.C.3.a', '2.C.1.c', '2.B.1.e', '1.A.1.d.1', '2.B.1.a', '1.A.1.b.1', '2.A.1.b', '2.A.1.c', '2.A.1.d', '2.A.1.e', '2.A.2.a', '2.A.2.b', '2.A.2.c', '2.A.2.d', '2.B.1.a', '2.B.1.b', '2.B.1.c', '2.B.1.d', '2.B.1.e', '2.B.2.i', '2.B.3.a', '2.B.4.e', '2.B.4.g', '2.B.4.h', '2.B.5.a', '2.B.5.b', '2.B.5.d', '1.A.1.a.1', '1.A.1.a.2', '1.A.1.a.3', '1.A.1.a.4', '1.A.1.b.1', '1.A.1.b.2', '1.A.1.b.3', '1.A.1.b.4', '1.A.1.b.5', '1.A.1.b.6', '1.A.1.b.7', '1.A.1.c.1', '1.A.1.c.2', '1.A.1.e.2', '1.A.4.a.1', '1.A.4.b.4', '1.A.4.b.5', '2.C.1.a', '2.C.1.b', '2.C.1.c', '2.C.1.e', '2.C.1.f', '2.C.4.a', '2.C.4.e', '2.C.6', '2.C.7.a', '2.C.8.b', '2.B.1.f', '2.C.3.a', '2.C.4.f', '2.C.4.g', '2.C.9.b', '1.A.1.d.1', '1.A.1.e.1', '2.C.4.d', '2.C.4.b', '2.C.5.b', '2.C.7.e', '2.A.1.f', '2.C.5.a'])\n",
      "120\n",
      "(('2.A.1.a', '2.C.4.d'), 0.9078947368421053)\n",
      "4322\n"
     ]
    }
   ],
   "source": [
    "z_thresh = 4.75\n",
    "skill_side_prj, skill_side_cp = projection_from_con(skill_occ_B.edges, axis = 1, zscore = z_thresh)\n",
    "\n",
    "print(list(skill_side_prj.items())[0])\n",
    "print(len(list(skill_side_prj.items())))\n",
    "print(list(skill_side_cp.items())[0])\n",
    "print(len(list(skill_side_cp.items())))\n",
    "    \n",
    "## The outcome is called Pruned graph in the paper.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Produce a Hierarchical Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Option: return graph object\n",
      "-Calculate the hierarchy measure, alpha\n",
      "=Complete the calculation of hierarhcy measure\n",
      "-Making graph object using NetworkX\n",
      "=Complete!\n",
      "previous number of edges:4322\n",
      "number of nodes left:115\n",
      "['2.A.1.a', '2.C.4.d', '1.A.1.b.2', '2.C.9.b', '2.C.5.b']\n",
      "number of edges left:1796\n",
      "[('2.A.1.a', '2.C.4.d'), ('2.A.1.a', '1.A.1.b.2'), ('2.A.1.a', '2.C.9.b'), ('2.A.1.a', '2.C.5.b'), ('2.A.1.a', '2.A.1.e')]\n",
      "[(('2.A.1.a', '2.C.4.d'), 0.2954), (('2.A.1.a', '1.A.1.b.2'), 0.2191), (('2.A.1.a', '2.C.9.b'), 0.4186), (('2.A.1.a', '2.C.5.b'), 0.4862), (('2.A.1.a', '2.A.1.e'), 0.3641)]\n"
     ]
    }
   ],
   "source": [
    "a_thresh = 0.05\n",
    "hierarchical_skill_G = extract_hierarchical_subgraph_from_edges(skill_side_prj, skill_side_cp, thres = a_thresh)\n",
    "\n",
    "print(\"previous number of edges:\" + str(len(list(skill_side_cp.items()))))\n",
    "\n",
    "print(\"number of nodes left:\" + str(len(hierarchical_skill_G.nodes)))\n",
    "print(list(hierarchical_skill_G.nodes)[:5])\n",
    "print(\"number of edges left:\" + str(len(hierarchical_skill_G.edges)))\n",
    "print(list(hierarchical_skill_G.edges)[:5])\n",
    "print(list(nx.get_edge_attributes(hierarchical_skill_G,'alpha').items())[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Dirty Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pos = nx.nx_agraph.graphviz_layout(hierarchical_skill_G, prog='dot')\n",
    "nx.draw(hierarchical_skill_G, node_size=50, pos=pos, width=list(nx.get_edge_attributes(hierarchical_skill_G,'alpha').values()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the graph without additional features for possible external use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         source     target   alpha             source_title  \\\n",
      "0       2.A.1.a    2.C.4.d  0.2954    Reading Comprehension   \n",
      "1     1.A.1.b.5    2.C.4.d  0.2778      Inductive Reasoning   \n",
      "2     1.A.1.b.4    2.C.4.d  0.2818      Deductive Reasoning   \n",
      "3     1.A.4.b.5    2.C.4.d  0.2151           Speech Clarity   \n",
      "4       2.C.4.a    2.C.4.d  0.2540    Mathematics Knowledge   \n",
      "...         ...        ...     ...                      ...   \n",
      "1791  1.A.3.c.3  1.A.3.c.2  0.0602  Gross Body Coordination   \n",
      "1792  1.A.3.a.3  1.A.3.c.2  0.0603         Dynamic Strength   \n",
      "1793  1.A.2.b.3  1.A.4.a.4  0.0608     Response Orientation   \n",
      "1794  1.A.1.f.1  1.A.4.a.4  0.0565      Spatial Orientation   \n",
      "1795  1.A.1.g.1  1.A.2.a.3  0.0578      Selective Attention   \n",
      "\n",
      "             target_title  \n",
      "0                 Biology  \n",
      "1                 Biology  \n",
      "2                 Biology  \n",
      "3                 Biology  \n",
      "4                 Biology  \n",
      "...                   ...  \n",
      "1791  Dynamic Flexibility  \n",
      "1792  Dynamic Flexibility  \n",
      "1793         Night Vision  \n",
      "1794         Night Vision  \n",
      "1795     Finger Dexterity  \n",
      "\n",
      "[1796 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Save hierarchical skill network edgelist\n",
    "hierarchical_skill_edgelist = nx.to_pandas_edgelist(hierarchical_skill_G)\n",
    "hierarchical_skill_edgelist = hierarchical_skill_edgelist. \\\n",
    "    merge(skills_names[[\"element_title\",\"element_ID\"]].rename(columns = {\"element_title\":\"source_title\", \"element_ID\":\"source\"}), on = \"source\"). \\\n",
    "    merge(skills_names[[\"element_title\",\"element_ID\"]].rename(columns = {\"element_title\":\"target_title\", \"element_ID\":\"target\"}), on = \"target\")\n",
    "\n",
    "print(hierarchical_skill_edgelist)\n",
    "hierarchical_skill_edgelist.\\\n",
    "    to_csv(basepath+'output_data/' \\\n",
    "           'hierarchical_skill_network_edgelist_z-thres_'+str(z_thresh)+'_a-thres_'+str(a_thresh)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Creating a Parsimonuous Grapgh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove 1402 direct paths in G\n",
      "number of nodes left:115\n",
      "number of edges left:394\n",
      "\n",
      "List of Missing Skills:\n",
      "       element_ID               element_title       type\n",
      "40        2.B.3.d                Installation      skill\n",
      "67824   1.A.3.a.2          Explosive Strength    ability\n",
      "67858   1.A.4.b.3          Sound Localization    ability\n",
      "168446    2.C.2.b             Food Production  knowledge\n",
      "168488    2.C.8.a  Public Safety and Security  knowledge\n"
     ]
    }
   ],
   "source": [
    "parsi_G = parsimony_network(hierarchical_skill_G)\n",
    "\n",
    "print(\"number of nodes left:\" + str(len(parsi_G.nodes)))\n",
    "print(\"number of edges left:\" + str(len(parsi_G.edges)))\n",
    "\n",
    "print(\"\\nList of Missing Skills:\")\n",
    "print(skills_names[~skills_names.element_ID.isin(list(e[0] for e in parsi_G.nodes(data=True)))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nx.draw(parsi_G, node_size=50, pos=nx.nx_agraph.graphviz_layout(parsi_G, prog='dot'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2.A.1.a', '1.A.1.b.5', {'alpha': 0.0879, 'alpha_sqrt': 0.29647934160747186}), ('2.A.1.a', '1.A.1.b.4', {'alpha': 0.0588, 'alpha_sqrt': 0.24248711305964282}), ('2.A.1.a', '2.C.4.a', {'alpha': 0.0532, 'alpha_sqrt': 0.2306512518934159}), ('2.A.1.a', '2.A.2.b', {'alpha': 0.0908, 'alpha_sqrt': 0.3013303834663873}), ('2.A.1.a', '2.B.4.e', {'alpha': 0.109, 'alpha_sqrt': 0.3301514803843836}), ('2.A.1.a', '2.B.1.b', {'alpha': 0.0615, 'alpha_sqrt': 0.24799193535274489}), ('2.A.1.a', '1.A.1.a.4', {'alpha': 0.0969, 'alpha_sqrt': 0.3112876483254676}), ('2.A.1.a', '2.A.1.d', {'alpha': 0.066, 'alpha_sqrt': 0.2569046515733026}), ('2.A.1.a', '2.C.6', {'alpha': 0.0585, 'alpha_sqrt': 0.24186773244895649}), ('2.C.4.d', '2.C.5.a', {'alpha': 0.0903, 'alpha_sqrt': 0.3004995840263344})]\n"
     ]
    }
   ],
   "source": [
    "##### Changing the direction of Edges so that arrow direction show dependency (child -> parent as opposed to parent -> child)\n",
    "for e, f, g in parsi_G.edges(data = True):\n",
    "    nx.set_edge_attributes(parsi_G, {(e, f): {\"alpha_sqrt\": np.sqrt(g['alpha'])}})\n",
    "\n",
    "for e, f, g in hierarchical_skill_G.edges(data = True):\n",
    "    nx.set_edge_attributes(hierarchical_skill_G, {(e, f): {\"alpha_sqrt\": np.sqrt(g['alpha'])}})\n",
    "\n",
    "    \n",
    "print(list(parsi_G.edges(data = True))[0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Z-layer Attribute based on Local Reaching Centrality - Used in Gephi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 115/115 [00:00<00:00, 501.42it/s]\n",
      "100%|████████████████████████████████████████| 115/115 [00:00<00:00, 658.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2.A.1.a': 62.03969274786624, '2.C.4.d': 0.9758932702239759, '1.A.1.b.2': 37.382999437546715, '2.C.9.b': 12.113167885508942, '2.C.5.b': 0.0, '2.A.1.e': 23.101712411748764, '2.B.5.b': 1.5017992291560522, '2.B.3.a': 4.775867247294729, '1.A.1.b.5': 50.12684630972392, '2.B.5.a': 35.24109622027696, '2.B.4.h': 30.847179650801955, '2.B.1.f': 34.55691214955679, '2.C.4.f': 6.793718948105963, '2.C.1.a': 37.889212212256616, '2.C.4.b': 0.0, '2.B.5.d': 18.36766486826223, '1.A.1.e.2': 44.151835766129615, '2.C.7.e': 2.0496746004128417, '1.A.1.b.4': 53.078812544092486, '1.A.1.c.2': 22.72269080123369, '2.C.8.b': 17.028019525341744, '2.C.1.b': 36.65242155349975, '1.A.4.b.5': 35.096557407766696, '2.B.1.d': 18.973092664007343, '2.A.1.f': 0.7292365510458529, '2.C.4.a': 46.608280666042326, '2.A.2.b': 50.070444303274876, '2.B.4.e': 53.41756068789664, '1.A.1.c.1': 23.44851277990787, '2.A.1.c': 52.204115766481195, '2.B.1.b': 41.47240168896855, '1.A.4.a.1': 70.76563404836213, '2.B.2.i': 50.665586817828796, '2.A.2.c': 33.09474150201321, '1.A.1.e.1': 1.0081649044158858, '1.A.1.a.3': 74.12471693211934, '2.C.4.g': 2.9038665994416943, '1.A.1.a.4': 50.725182293012615, '2.C.5.a': 0.0, '2.A.1.d': 53.011282818536195, '2.B.4.g': 28.237409576680644, '2.B.1.c': 31.444405643382815, '2.C.4.e': 22.33615543578119, '2.C.1.f': 13.103739191438466, '2.C.6': 40.995084847726574, '1.A.1.a.1': 74.63126482690666, '2.C.1.c': 3.510966375914742, '2.B.1.e': 37.11731857578987, '1.A.1.d.1': 0.973741486850695, '2.B.1.a': 36.67987827179028, '1.A.1.b.1': 39.026213881285656, '2.A.1.b': 62.01198070185906, '2.C.1.d': 3.7580324852127087, '2.B.5.c': 0.0, '1.A.1.b.6': 61.11498159689248, '2.C.7.a': 59.89680816182226, '1.A.1.b.3': 54.9589572714818, '2.A.2.a': 62.01288447503969, '2.C.7.d': 0.0, '2.A.2.d': 58.664917241642044, '1.A.1.b.7': 62.90922286299939, '2.C.1.e': 55.958071450086905, '1.A.4.b.4': 58.323033345681594, '1.A.1.a.2': 63.02379386764899, '2.C.3.a': 58.21342533017234, '2.B.3.e': 0.0, '2.B.3.b': 0.0, '1.A.1.g.2': 3.4615557186132095, '2.C.3.b': 17.007755938825174, '2.C.7.c': 0.0, '2.C.4.c': 0.0, '1.A.1.e.3': 24.641264180372833, '1.A.1.f.2': 32.15425116041603, '2.B.3.h': 15.060852293614014, '1.A.2.b.4': 5.985799195260516, '2.B.3.l': 0.0, '1.A.2.c.1': 17.54392910553717, '1.A.3.a.4': 17.26636625186038, '1.A.2.b.2': 23.869824163618407, '2.C.3.c': 1.3089051663444289, '1.A.2.a.2': 25.125199842376485, '2.B.3.j': 0.0, '2.B.3.m': 15.756254909732665, '1.A.2.a.1': 24.579314570512793, '1.A.4.a.6': 10.120153460329481, '2.C.2.a': 19.50874184772964, '1.A.4.a.3': 12.316723204519693, '1.A.2.b.1': 24.120437561189327, '2.B.3.g': 18.752930327853495, '1.A.3.a.1': 17.87682871558018, '2.C.3.d': 2.012915765858859, '2.B.3.k': 6.020210457810474, '1.A.4.b.2': 14.859068335477787, '1.A.3.c.1': 17.478455681960156, '2.C.9.a': 0.0, '2.C.3.e': 27.5152190321119, '1.A.3.c.4': 1.246677338165484, '2.C.7.b': 0.0, '1.A.4.a.2': 19.91402693174839, '1.A.2.b.3': 4.0446378114347885, '1.A.1.g.1': 33.82668498918971, '1.A.2.a.3': 27.40730217825117, '1.A.4.b.1': 1.05117883424519, '1.A.1.f.1': 1.612023537368413, '1.A.4.a.7': 0.0, '2.B.3.c': 0.0, '2.C.10': 3.7251694240818347, '1.A.4.a.5': 0.0, '1.A.3.c.3': 2.087485921471976, '1.A.2.c.3': 0.0, '1.A.3.b.1': 3.3161720534145855, '1.A.3.a.3': 1.8934968850266147, '1.A.2.c.2': 0.0, '1.A.3.c.2': 0.0, '1.A.4.a.4': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for s in tqdm(parsi_G.nodes):\n",
    "    nx.set_node_attributes(parsi_G, {s: {\"LRC\": nx.local_reaching_centrality(parsi_G, s, weight = \"alpha\", normalized = True)}})\n",
    "    nx.set_node_attributes(parsi_G, {s: {\"LRC_norm\": math.floor(100 * nx.local_reaching_centrality(parsi_G, s, weight = \"alpha\", normalized = True))}})\n",
    "    nx.set_node_attributes(parsi_G, {s: {\"LRC_modif\": (250 * np.log10(1 + nx.local_reaching_centrality(parsi_G, s, weight = \"alpha\", normalized = True)))}})\n",
    "    nx.set_node_attributes(parsi_G, {s: {\"LRC_non_parsi_modif\": (250 * np.log10(1 + nx.local_reaching_centrality(hierarchical_skill_G, s, weight = \"alpha\", normalized = True)))}})\n",
    "    nx.set_node_attributes(hierarchical_skill_G, {s: {\"LRC_non_parsi\": nx.local_reaching_centrality(hierarchical_skill_G, s, weight = \"alpha\", normalized = True)}})\n",
    "\n",
    "    \n",
    "for s in tqdm(hierarchical_skill_G.nodes):\n",
    "    nx.set_node_attributes(hierarchical_skill_G, {s: {\"LRC\": nx.local_reaching_centrality(hierarchical_skill_G, s, weight = \"alpha\", normalized = True)}})\n",
    "    nx.set_node_attributes(hierarchical_skill_G, {s: {\"LRC_norm\": math.floor(100 * nx.local_reaching_centrality(hierarchical_skill_G, s, weight = \"alpha\", normalized = True))}})\n",
    "    nx.set_node_attributes(hierarchical_skill_G, {s: {\"LRC_modif\": (250 * np.log10(1 + nx.local_reaching_centrality(hierarchical_skill_G, s, weight = \"alpha\", normalized = True)))}})\n",
    "\n",
    "\n",
    "\n",
    "z_vals = nx.get_node_attributes(parsi_G,\"LRC\")\n",
    "\n",
    "# Save Local Reaching Centrality measures for both networks\n",
    "pd.DataFrame.from_dict(nx.get_node_attributes(hierarchical_skill_G,\"LRC\"), orient = \"index\")\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns = {'index': 'element_ID', 0:'LRC'})\\\n",
    "    .to_csv(basepath+'output_data/' \\\n",
    "           'skill_dependency_network_LRC_measures.csv', index=False)\n",
    "\n",
    "pd.DataFrame.from_dict(nx.get_node_attributes(parsi_G,\"LRC\"), orient = \"index\")\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns = {'index': 'element_ID', 0:'LRC'})\\\n",
    "    .to_csv(basepath+'output_data/' \\\n",
    "           'parsimonious_skill_dependency_network_LRC_measures.csv', index=False)\n",
    "\n",
    "\n",
    "print(nx.get_node_attributes(parsi_G,\"LRC_modif\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Node Feature as Ancestors of a few Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID  Prog_cum_dep  Repr_cum_dep  Nego_cum_dep  Prog_norm_dep  \\\n",
      "0  1.A.1.a.1      0.135337      0.000100      0.040161       0.135337   \n",
      "1  1.A.1.a.2      0.133336      0.000055      0.038556       0.133336   \n",
      "2  1.A.1.a.3      0.136986      0.000100      0.041227       0.136986   \n",
      "3  1.A.1.a.4      0.124314      0.000024      0.035521       0.124314   \n",
      "4  1.A.1.b.1      0.156736      0.000000      0.035617       0.156736   \n",
      "\n",
      "   Repr_norm_dep  Nego_norm_dep  \n",
      "0       0.000324       0.589696  \n",
      "1       0.000177       0.566132  \n",
      "2       0.000325       0.605344  \n",
      "3       0.000076       0.521559  \n",
      "4       0.000000       0.522981  \n"
     ]
    }
   ],
   "source": [
    "# Load skill dependency data computed using Baldwin (2010) method\n",
    "skill_dependency_df = pd.read_csv(basepath+'processed_data/skill_dependency_data_baldwin_method.csv')\n",
    "\n",
    "print(skill_dependency_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Step: Adding Other Attribures and Save Graph as Gephi File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  element_ID          element_title   type skill_Cluster gen_related  \\\n",
      "0    2.A.1.a  Reading Comprehension  skill       General     General   \n",
      "1    2.A.1.b       Active Listening  skill       General     General   \n",
      "2    2.A.1.c                Writing  skill       General     General   \n",
      "3    2.A.1.d               Speaking  skill       General     General   \n",
      "4    2.A.2.a      Critical Thinking  skill       General     General   \n",
      "\n",
      "                                              viz  Imp_weight_Avg_Edu  \\\n",
      "0  {'color': {'r': 230, 'g': 7, 'b': 42, 'a': 1}}               5.007   \n",
      "1  {'color': {'r': 230, 'g': 7, 'b': 42, 'a': 1}}               4.914   \n",
      "2  {'color': {'r': 230, 'g': 7, 'b': 42, 'a': 1}}               5.079   \n",
      "3  {'color': {'r': 230, 'g': 7, 'b': 42, 'a': 1}}               4.928   \n",
      "4  {'color': {'r': 230, 'g': 7, 'b': 42, 'a': 1}}               4.934   \n",
      "\n",
      "   Lvl_weight_Avg_Edu  Lvl_weight_2005limited_Edu  log_wage  \n",
      "0               5.198                       5.463     4.796  \n",
      "1               5.059                       5.317     4.786  \n",
      "2               5.238                       5.512     4.799  \n",
      "3               5.117                       5.389     4.790  \n",
      "4               5.048                       5.302     4.788  \n",
      "[('2.A.1.a', {'element_title': 'Reading Comprehension', 'type': 'skill', 'skill_Cluster': 'General', 'gen_related': 'General', 'viz': {'color': {'r': 230, 'g': 7, 'b': 42, 'a': 1}}, 'Imp_weight_Avg_Edu': 5.007, 'Lvl_weight_Avg_Edu': 5.198, 'Lvl_weight_2005limited_Edu': 5.463, 'log_wage': 4.796}), ('2.A.1.b', {'element_title': 'Active Listening', 'type': 'skill', 'skill_Cluster': 'General', 'gen_related': 'General', 'viz': {'color': {'r': 230, 'g': 7, 'b': 42, 'a': 1}}, 'Imp_weight_Avg_Edu': 4.914, 'Lvl_weight_Avg_Edu': 5.059, 'Lvl_weight_2005limited_Edu': 5.317, 'log_wage': 4.786}), ('2.A.1.c', {'element_title': 'Writing', 'type': 'skill', 'skill_Cluster': 'General', 'gen_related': 'General', 'viz': {'color': {'r': 230, 'g': 7, 'b': 42, 'a': 1}}, 'Imp_weight_Avg_Edu': 5.079, 'Lvl_weight_Avg_Edu': 5.238, 'Lvl_weight_2005limited_Edu': 5.512, 'log_wage': 4.799}), ('2.A.1.d', {'element_title': 'Speaking', 'type': 'skill', 'skill_Cluster': 'General', 'gen_related': 'General', 'viz': {'color': {'r': 230, 'g': 7, 'b': 42, 'a': 1}}, 'Imp_weight_Avg_Edu': 4.928, 'Lvl_weight_Avg_Edu': 5.117, 'Lvl_weight_2005limited_Edu': 5.389, 'log_wage': 4.79}), ('2.A.2.a', {'element_title': 'Critical Thinking', 'type': 'skill', 'skill_Cluster': 'General', 'gen_related': 'General', 'viz': {'color': {'r': 230, 'g': 7, 'b': 42, 'a': 1}}, 'Imp_weight_Avg_Edu': 4.934, 'Lvl_weight_Avg_Edu': 5.048, 'Lvl_weight_2005limited_Edu': 5.302, 'log_wage': 4.788})]\n",
      "['2.A.1.a', '2.C.4.d', '1.A.1.b.2', '2.C.9.b', '2.C.5.b']\n",
      "[('2.A.1.a', '1.A.1.b.5'), ('2.A.1.a', '1.A.1.b.4'), ('2.A.1.a', '2.C.4.a'), ('2.A.1.a', '2.A.2.b'), ('2.A.1.a', '2.B.4.e')]\n",
      "[(('2.A.1.a', '1.A.1.b.5'), 0.0879), (('2.A.1.a', '1.A.1.b.4'), 0.0588), (('2.A.1.a', '2.C.4.a'), 0.0532), (('2.A.1.a', '2.A.2.b'), 0.0908), (('2.A.1.a', '2.B.4.e'), 0.109)]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#### Saving Node Names, Education, and Clusters as dictionary files\n",
    "skill_names_and_clusters = skills_names[[\"element_ID\", \"element_title\", \"type\"]] \\\n",
    "    .merge(skill_clusters[[\"element_ID\", \"skill_Cluster\", \"gen_related\"]], on = \"element_ID\") \\\n",
    "    .merge(pd.DataFrame([[\"General\",{'color':{'r': 230, 'g': 7, 'b': 42, 'a': 1}}], [\"Intermediate\",{'color':{'r': 190, 'g': 190, 'b': 190, 'a': 1}}], [\"Specific\",{'color':{'r': 66, 'g':79, 'b': 164, 'a': 1}}]], columns = [\"skill_Cluster\",\"viz\"]), on = \"skill_Cluster\") \\\n",
    "    .merge(skill_educ, on = 'element_ID') \\\n",
    "    .merge(skill_educ_2005limited, on = 'element_ID') \\\n",
    "    .merge(skill_wages, on = 'element_ID')\n",
    "\n",
    "print(skill_names_and_clusters.head())\n",
    "\n",
    "skill_names_and_clusters = skill_names_and_clusters.set_index('element_ID').T.to_dict('dict')\n",
    "\n",
    "print(list(skill_names_and_clusters.items())[:5])\n",
    "\n",
    "#### Adding these attributes to the graph\n",
    "nx.set_node_attributes(hierarchical_skill_G, skill_names_and_clusters)\n",
    "nx.set_node_attributes(parsi_G, skill_names_and_clusters)\n",
    "\n",
    "# print(skill_names_and_clusters.head())\n",
    "print(list(parsi_G.nodes)[:5])\n",
    "print(list(parsi_G.edges)[:5])\n",
    "print(list(nx.get_edge_attributes(parsi_G,'alpha').items())[:5])\n",
    "print(list(nx.get_node_attributes(parsi_G,'[z]').items())[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Edge Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "color_mapping = {\n",
    "    'General': {'r': 230, 'g': 7, 'b': 42, 'a': 1},\n",
    "    'Intermediate': {'r': 89, 'g': 89, 'b': 89, 'a': 1},\n",
    "    'Specific': {'r': 66, 'g': 79, 'b': 164, 'a': 1}\n",
    "}\n",
    "\n",
    "# Assign colors to edges based on the parent node's skill_cluster\n",
    "for u, v in parsi_G.edges():\n",
    "    parent_skill_cluster = parsi_G.nodes[u]['skill_Cluster']\n",
    "    edge_color = color_mapping.get(parent_skill_cluster, {'r': 0, 'g': 0, 'b': 0, 'a': 1})\n",
    "    parsi_G[u][v]['viz'] = {'color': edge_color}\n",
    "    \n",
    "    \n",
    "for u, v in hierarchical_skill_G.edges():\n",
    "    parent_skill_cluster = hierarchical_skill_G.nodes[u]['skill_Cluster']\n",
    "    edge_color = color_mapping.get(parent_skill_cluster, {'r': 0, 'g': 0, 'b': 0, 'a': 1})\n",
    "    hierarchical_skill_G[u][v]['viz'] = {'color': edge_color}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save networks in GEXF format for visualization in Gephi\n",
    "nx.write_gexf(parsi_G, \\\n",
    "              basepath + 'output_data/gephi_files/' + \\\n",
    "              'parsimonious_skill_network_z-thres_' + str(z_thresh) + '_a-thres_' + str(a_thresh) + '.gexf')\n",
    "\n",
    "nx.write_gexf(hierarchical_skill_G, \\\n",
    "              basepath + 'output_data/gephi_files/' + \\\n",
    "              'hierarchical_skill_network_z-thres_' + str(z_thresh) + '_a-thres_' + str(a_thresh) + '.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    source     target   alpha\n",
      "0  2.A.1.a  1.A.1.a.4  0.0969\n",
      "1  2.A.1.a  1.A.1.b.5  0.0879\n",
      "2  2.A.1.a  1.A.1.b.4  0.0588\n",
      "3  2.A.1.a    2.C.4.a  0.0532\n",
      "4  2.A.1.a    2.A.1.d  0.0660\n",
      "        ID                  Title   type skill_Cluster  \\\n",
      "0  2.A.1.a  Reading Comprehension  skill       General   \n",
      "1  2.A.1.b       Active Listening  skill       General   \n",
      "2  2.A.1.c                Writing  skill       General   \n",
      "3  2.A.1.d               Speaking  skill       General   \n",
      "4  2.A.2.a      Critical Thinking  skill       General   \n",
      "\n",
      "                                             viz simple_color  \\\n",
      "0  {'color': {'r': 255, 'g': 0, 'b': 0, 'a': 0}}            r   \n",
      "1  {'color': {'r': 255, 'g': 0, 'b': 0, 'a': 0}}            r   \n",
      "2  {'color': {'r': 255, 'g': 0, 'b': 0, 'a': 0}}            r   \n",
      "3  {'color': {'r': 255, 'g': 0, 'b': 0, 'a': 0}}            r   \n",
      "4  {'color': {'r': 255, 'g': 0, 'b': 0, 'a': 0}}            r   \n",
      "\n",
      "   Imp_weight_Avg_Edu  Lvl_weight_Avg_Edu  specialty  \n",
      "0               5.007               5.198 -13.915165  \n",
      "1               4.914               5.059 -16.310574  \n",
      "2               5.079               5.238 -14.110058  \n",
      "3               4.928               5.117 -12.772856  \n",
      "4               4.934               5.048 -16.343118  \n"
     ]
    }
   ],
   "source": [
    "parsi_G_edgelist = nx.to_pandas_edgelist(parsi_G)\n",
    "\n",
    "## Saving the Parsimonious Network Edgelist\n",
    "parsi_G_edgelist.\\\n",
    "    to_csv(basepath+'output_data/' \\\n",
    "           'parsimonious_skill_dependency_edgelist.csv', index=False)\n",
    "\n",
    "print(parsi_G_edgelist.head())\n",
    "\n",
    "parsi_G_nodelist = skills_names[[\"element_ID\", \"element_title\", \"type\"]] \\\n",
    "    .merge(skill_clusters[[\"element_ID\", \"skill_Cluster\"]], on = \"element_ID\") \\\n",
    "    .merge(pd.DataFrame([[\"General\",{'color':{'r': 255, 'g': 0, 'b': 0, 'a': 0}}], [\"Common\",{'color':{'r': 0, 'g': 255, 'b': 0, 'a': 0}}], [\"Specific\",{'color':{'r': 0, 'g': 0, 'b': 255, 'a': 0}}]], columns = [\"skill_Cluster\",\"viz\"]), on = \"skill_Cluster\") \\\n",
    "    .merge(pd.DataFrame([[\"General\",'r'], [\"Common\",'g'], [\"Specific\",'b']], columns = [\"skill_Cluster\",\"simple_color\"]), on = \"skill_Cluster\") \\\n",
    "    .merge(skill_educ, on = 'element_ID') \\\n",
    "    .merge(skill_nested, on = 'element_ID').rename(columns = {'element_ID':'ID', \"element_title\":\"Title\", \"c_i\":'specialty'})\n",
    "\n",
    "print(parsi_G_nodelist.head())\n",
    "\n",
    "## Saving the Parsimonious Network Nodelist\n",
    "parsi_G_nodelist.\\\n",
    "    to_csv(basepath+'output_data/' \\\n",
    "           'parsimonious_skill_dependency_nodelist.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving The Edge List of Parsimonious Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsi_G_edgelist = nx.to_pandas_edgelist(parsi_G)\n",
    "\n",
    "# Save parsimonious network edgelist\n",
    "parsi_G_edgelist.\\\n",
    "    to_csv(basepath+'output_data/' \\\n",
    "           'parsimonious_network_edgelist_z-thres_'+str(z_thresh)+'_a-thres_'+str(a_thresh)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
